{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24eb4180-3b4c-4331-b7e6-981a297ed433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed segment_1.mp4: 2 segments created\n",
      "Processed segment_10.mp4: 1 segments created\n",
      "Processed segment_2.mp4: 2 segments created\n",
      "Processed segment_3.mp4: 3 segments created\n",
      "Processed segment_4.mp4: 2 segments created\n",
      "Processed segment_5.mp4: 2 segments created\n",
      "Processed segment_6.mp4: 2 segments created\n",
      "Processed segment_7.mp4: 1 segments created\n",
      "Processed segment_8.mp4: 2 segments created\n",
      "Processed segment_9.mp4: 2 segments created\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "class VideoSegmenter:\n",
    "   def __init__(self, similarity_threshold=0.85):\n",
    "       self.model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "       self.model = torch.nn.Sequential(*list(self.model.children())[:-1])\n",
    "       self.model.eval()\n",
    "       self.transform = transforms.Compose([\n",
    "           transforms.ToPILImage(),\n",
    "           transforms.Resize((224, 224)),\n",
    "           transforms.ToTensor(),\n",
    "           transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "       ])\n",
    "       self.similarity_threshold = similarity_threshold\n",
    "\n",
    "   def extract_features(self, frame):\n",
    "       frame_tensor = self.transform(frame).unsqueeze(0)\n",
    "       with torch.no_grad():\n",
    "           features = self.model(frame_tensor)\n",
    "       return features.squeeze()\n",
    "\n",
    "   def compute_similarity(self, feat1, feat2):\n",
    "       return torch.cosine_similarity(feat1.unsqueeze(0), \n",
    "                                    feat2.unsqueeze(0)).item()\n",
    "\n",
    "   def segment_video(self, video_path, output_dir):\n",
    "       Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "       \n",
    "       cap = cv2.VideoCapture(video_path)\n",
    "       fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "       frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "       \n",
    "       segments = []\n",
    "       current_segment = []\n",
    "       prev_features = None\n",
    "       frame_interval = 8\n",
    "       \n",
    "       video_name = Path(video_path).stem\n",
    "       \n",
    "       for frame_idx in range(0, frame_count, frame_interval):\n",
    "           cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "           ret, frame = cap.read()\n",
    "           if not ret:\n",
    "               break\n",
    "               \n",
    "           current_features = self.extract_features(frame)\n",
    "           \n",
    "           if prev_features is None:\n",
    "               current_segment.append(frame_idx)\n",
    "               prev_features = current_features\n",
    "               continue\n",
    "               \n",
    "           similarity = self.compute_similarity(prev_features, current_features)\n",
    "           \n",
    "           if similarity < self.similarity_threshold:\n",
    "               current_segment.append(frame_idx - frame_interval)\n",
    "               segments.append(current_segment)\n",
    "               current_segment = [frame_idx]\n",
    "               \n",
    "           prev_features = current_features\n",
    "           \n",
    "       if current_segment:\n",
    "           current_segment.append(frame_idx)\n",
    "           segments.append(current_segment)\n",
    "           \n",
    "       for i, (start, end) in enumerate(segments):\n",
    "           segment_time_start = start / fps\n",
    "           segment_time_end = end / fps\n",
    "           output_filename = f'{video_name}_segment_{i}_{segment_time_start:.2f}-{segment_time_end:.2f}.mp4'\n",
    "           output_path = os.path.join(output_dir, output_filename)\n",
    "           self._save_segment(video_path, output_path, start, end, fps)\n",
    "           \n",
    "       cap.release()\n",
    "       return segments\n",
    "\n",
    "   def _save_segment(self, input_path, output_path, start_frame, end_frame, fps):\n",
    "       cap = cv2.VideoCapture(input_path)\n",
    "       cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "       \n",
    "       fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "       out = None\n",
    "       \n",
    "       while cap.get(cv2.CAP_PROP_POS_FRAMES) <= end_frame:\n",
    "           ret, frame = cap.read()\n",
    "           if not ret:\n",
    "               break\n",
    "               \n",
    "           if out is None:\n",
    "               height, width = frame.shape[:2]\n",
    "               out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "               \n",
    "           out.write(frame)\n",
    "           \n",
    "       cap.release()\n",
    "       if out:\n",
    "           out.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   # For video segmentation\n",
    "   video_dir = r\"C:\\Users\\admin\\film_dataset\"\n",
    "   segments_dir = r\"C:\\Users\\admin\\film_dataset\\all_segments\"\n",
    "   \n",
    "   # First segment videos\n",
    "   segmenter = VideoSegmenter(similarity_threshold=0.85)\n",
    "   Path(segments_dir).mkdir(parents=True, exist_ok=True)\n",
    "   \n",
    "   for video_file in Path(video_dir).glob(\"*.mp4\"):\n",
    "       segments = segmenter.segment_video(str(video_file), segments_dir)\n",
    "       print(f\"Processed {video_file.name}: {len(segments)} segments created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d314914-ff54-478e-acf9-e1fdd635020e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top similar segments with full paths:\n",
      "Segment path: C:\\Users\\admin\\film_dataset\\all_segments\\segment_8_segment_1_2.67-6.13.mp4, Similarity: 0.9860\n",
      "Segment path: C:\\Users\\admin\\film_dataset\\all_segments\\segment_9_segment_0_0.00-1.87.mp4, Similarity: 0.9161\n",
      "Segment path: C:\\Users\\admin\\film_dataset\\all_segments\\segment_9_segment_1_2.13-6.13.mp4, Similarity: 0.8748\n",
      "Segment path: C:\\Users\\admin\\film_dataset\\all_segments\\segment_4_segment_0_0.00-1.60.mp4, Similarity: 0.7882\n",
      "Segment path: C:\\Users\\admin\\film_dataset\\all_segments\\segment_2_segment_1_3.20-6.13.mp4, Similarity: 0.7874\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "class VideoMatcher:\n",
    "   def __init__(self):\n",
    "       self.model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "       self.model = torch.nn.Sequential(*list(self.model.children())[:-1]) \n",
    "       self.model.eval()\n",
    "       self.transform = transforms.Compose([\n",
    "           transforms.ToPILImage(),\n",
    "           transforms.Resize((224, 224)),\n",
    "           transforms.ToTensor(),\n",
    "           transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "       ])\n",
    "\n",
    "   def get_segment_features(self, video_path, sample_rate=8):\n",
    "       features = []\n",
    "       cap = cv2.VideoCapture(video_path)\n",
    "       frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "       \n",
    "       for frame_idx in range(0, frame_count, sample_rate):\n",
    "           cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "           ret, frame = cap.read()\n",
    "           if not ret:\n",
    "               break\n",
    "               \n",
    "           frame_tensor = self.transform(frame).unsqueeze(0)\n",
    "           with torch.no_grad():\n",
    "               feat = self.model(frame_tensor)\n",
    "           features.append(feat.squeeze().numpy())\n",
    "           \n",
    "       cap.release()\n",
    "       return np.mean(features, axis=0)\n",
    "\n",
    "   def search_segments(self, query_segment, segments_dir, top_k=5):\n",
    "       query_features = self.get_segment_features(query_segment)\n",
    "       \n",
    "       results = []\n",
    "       for segment_path in Path(segments_dir).glob(\"segment_*.mp4\"):\n",
    "           segment_features = self.get_segment_features(str(segment_path))\n",
    "           similarity = cosine_similarity([query_features], [segment_features])[0][0]\n",
    "           results.append((segment_path, similarity))\n",
    "           \n",
    "       results.sort(key=lambda x: x[1], reverse=True)\n",
    "       return results[:top_k]\n",
    "\n",
    "query_path = r\"C:\\Users\\admin\\segment_8_scene_7_140_3.20-4.27.mp4\"\n",
    "segments_dir = r\"C:\\Users\\admin\\film_dataset\\all_segments\"  \n",
    "\n",
    "matcher = VideoMatcher()\n",
    "similar_segments = matcher.search_segments(query_path, segments_dir)\n",
    "\n",
    "print(\"\\nTop similar segments with full paths:\")\n",
    "for path, similarity in similar_segments:\n",
    "   print(f\"Segment path: {path.absolute()}, Similarity: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9100f0c4-a0f4-476b-8f5c-d4f244012717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
